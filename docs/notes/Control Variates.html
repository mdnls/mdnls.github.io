
<!DOCTYPE html>
    <head>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" type="text/css" href="../styles/styles.css">
        <link rel="icon" href="assets/icon.ico" />
        <meta name="google-site-verification" content="gGsyj98Hmr9mZj0-DQzJIAdOP3eJXZJZnM4_NF8Mai8" />
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"> 
        <title>Mara Daniels - MIT</title>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
            onload="renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                ],
                macros: {
                    '\\saeq': '\\{#1\\}',
                    '\\linf': '\\lim_{n \\to \\infty}',
                    '\\Alpha': '\\mathcal{A}',
                    '\\norm': '\\left\\lVert#1\\right\\rVert',
                    '\\ct': 'C^\\infty_c ( #1 )',
                    '\\lloc': 'L^1_{\\mathsf{loc}}( #1 )',
                    '\\Scr': '\\mathscr{S}',
                    '\\tmpr': '\\mathscr{S}',
                    '\\limnf': '\\liminf \\limits_{#1}',
                    '\\limsp': '\\limsup \\limits_{#1}',
                    '\\R': '{\\mathbb R}',
                    '\\C': '{\\mathbb C}',
                    '\\N': '{\\mathbb N}',
                    '\\Q': '{\\mathbb Q}',
                    '\\H': '{\\mathbb H}',
                    '\\S': '{\\mathbb S}',
                    '\\Z': '{\\mathbb Z}',
                    '\\E': '{\\mathbb E}',
                    '\\Var': '\\mathsf{Var}',
                    '\\Cov': '\\mathsf{Cov}',
                    '\\KL': '\\mathsf{KL}',
                    '\\Ent': '\\mathsf{Ent}',
                    '\\F': '{\\mathbb F}',
                    '\\Acl': '\\mathcal{A}',
                    '\\Bcl': '\\mathcal{B}',
                    '\\Ccl': '\\mathcal{C}',
                    '\\Dcl': '\\mathcal{D}',
                    '\\Ecl': '\\mathcal{E}',
                    '\\Fcl': '\\mathcal{F}',
                    '\\Gcl': '\\mathcal{G}',
                    '\\Hcl': '\\mathcal{H}',
                    '\\Jcl': '\\mathcal{J}',
                    '\\Kcl': '\\mathcal{K}',
                    '\\Lcl': '\\mathcal{L}',
                    '\\Mcl': '\\mathcal{M}',
                    '\\Ncl': '\\mathcal{N}',
                    '\\Ocl': '\\mathcal{O}',
                    '\\Pcl': '\\mathcal{P}',
                    '\\Qcl': '\\mathcal{Q}',
                    '\\Rcl': '\\mathcal{R}',
                    '\\Scl': '\\mathcal{S}',
                    '\\Tcl': '\\mathcal{T}',
                    '\\Ucl': '\\mathcal{U}',
                    '\\Vcl': '\\mathcal{V}',
                    '\\Wcl': '\\mathcal{W}',
                    '\\Xcl': '\\mathcal{X}',
                    '\\Ycl': '\\mathcal{Y}',
                    '\\Zcl': '\\mathcal{Z}',
                    '\\diag': '\\mathrm{diag}',
                    '\\supp': '\\mathrm{supp}',
                    '\\diam': '\\mathrm{diam}',
                    '\\sgn': '\\mathrm{sgn}',
                    '\\im': '\\mathrm{Im}',
                    '\\lcm': '\\mathrm{lcm}',
                    '\\aut': '\\mathrm{Aut}',
                    '\\inn': '\\mathrm{Inn}',
                    '\\rg': '\\mathrm{rg}',
                    '\\vol': '\\mathrm{vol}',
                    '\\Pr': '\\mathrm{Pr}',
                    '\\Tr': '\\mathrm{Tr}',
                    '\\eps': '\\varepsilon',
                    '\\charfct': '\\mathds{1}',
                    '\\nullfct': '{\\bf 0}',
                    '\\as': '\\text{a.s.}\\xspace',
                    '\\argmax': '\\mathop{\\mathrm{arg\\,max}}',
                    '\\argmin': '\\mathop{\\mathrm{arg\\,min}}',
                    '\\esssup': '\\mathop{\\mathrm{ess\\,sup}}',
                    '\\th': '\\hat{\\theta}',
                    '\\pto': '\\stackrel{p}{\\longrightarrow}',
                    '\\dto': '\\stackrel{d}{\\longrightarrow}',
                    '\\asto': '\\stackrel{a.s.}{\\longrightarrow}',
                    '\\coloneqq': ':='
                }
            });">
            </script>
    </head>
    <body>
        <div class="row">
            <div class="col-lg-12 col-xl-8 offset-xl-2"> 
            <h1>Control Variates</h1>
<p>
Suppose that we would like to construct a Monte-Carlo estimate of the random variable $X : \Omega \to \R$ and that we have access to a correlated r.v. $Y : \Omega \to \R$ for which we can analytically compute $\mu_y = \E[Y]$. Define,
$$
Z = X - c(Y - \mu_y) \quad \implies \quad \E[Z] = \E[X].
$$
In some cases, a smart choice of $Y$ can reduce the variance of $Z$!
</p>
<p>
<strong>Example (Linearization)</strong>: suppose $X = f(\omega)$ where $\omega \in \R^d$ is a simple random variable, and $f : \R^d \to \R^k$ is a complicated function. Estimating the average of $X$ might require many evaluations of $f$. We can choose $Y = \bar{f}(\omega)$, where $\bar{f}$ is a linearization of $f$ (for example: linear regression of $X$ against $\omega$).
</p>
<p>
<strong>Algorithm</strong>: given samples $(X_i, Y_i)$ for $i = 1, \ldots, m$ and a hyperparameter $c \in \R$.
</p>
<ol>
<li>Write $Z_i = X_i - c(Y_i - \mu_Y)$.
</li>
<li>Compute the vanilla Monte-Carlo estimate of $\E[Z] = \E[X]$,
</li>
</ol>
<p>
$$
\hat{x}^{\mathsf{cv}}_n =  \frac{1}{m}\sum_{i=1}^m (X_i - c(Y_i - \mu_y))
$$
</p>
<p>
<strong>Analysis</strong>: the key questions are,
</p>
<ul>
<li>What is the variance of $\hat{x}^{\mathsf{cv}}_n$? $$
</li>
</ul>
<p>
\Var(\hat{x}^{\mathsf{cv}}<em>n) = \frac{1}{m} \Var(X + c(Y- \mu</em>y))  = \frac{1}{m} \left( \Var(X) + c^2 \Var(y) - 2c \Cov[X, Y]\right) $$
</p>
<ul>
<li>What is the optimal choice of $c>0$ to minimize variance? The variance above is quadratic in $c$, minimized at $c = \frac{\Cov[X, Y]}{\Var(X)}$ which leads to
</li>
</ul>
<p>
$$\Var(\hat{x}^{\mathsf{cv}}_m) = \frac{1}{m}\left(\Var(x) -  \frac{(\Cov[X, Y])^2}{\Var{Y}} \right)  $$
which is a strict improvement!
</p>
<p>
<em>Note</em>: in order to choose $c$ optimally, we have to know $\Cov[X, Y]$, which is not necessarily easier than estimating $\E[X]$ directly. In applied settings, we hope that (1) estimating $\Cov[X, Y]$ is easier than $\E[X]$ and that (2) choosing $c$ suboptimally (due to statistical error) still gives good variance reduction.
</p>
<p>
<strong>Discussion & Applications</strong>: generally speaking, the idea behind this method is to improve a Monte-Carlo estimate of $X$ using a simpler random variable $Y$, which is sometimes called the "surrogate model" or "reduced order model." In different applications, there are lots of names for related ideas:
</p>
<ul>
<li><em>Multi-fidelity Monte Carlo</em>: a Monte-Carlo method that leverages models of multiple fidelities to reduce the cost of estimating a high-fidelity parameter.
</li>
<li><em>Multi-level Monte Carlo</em>: a technique for PDE methods that involves <em>multiple</em> control variates of increasing complexity. These approaches often intelligently choose the control variates based on the decay rate of errors in the PDE solver at (for example) different discretization levels.
</li>
</ul>
            </div>
        </div>
        <div class="row">
        <p style="text-align: right; width:100%"><i><a href="../miscellany.html">Back...</a></i></p>
        </div>
    </body>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
    crossorigin="anonymous"></script>
</html>
