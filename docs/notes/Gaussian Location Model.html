
<!DOCTYPE html>
    <head>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" type="text/css" href="../styles/styles.css">
        <link rel="icon" href="assets/icon.ico" />
        <meta name="google-site-verification" content="gGsyj98Hmr9mZj0-DQzJIAdOP3eJXZJZnM4_NF8Mai8" />
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"> 
        <title>Mara Daniels - MIT</title>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
            onload="renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                ],
                macros: {
                    '\\saeq': '\\{#1\\}',
                    '\\linf': '\\lim_{n \\to \\infty}',
                    '\\Alpha': '\\mathcal{A}',
                    '\\norm': '\\left\\lVert#1\\right\\rVert',
                    '\\ct': 'C^\\infty_c ( #1 )',
                    '\\lloc': 'L^1_{\\mathsf{loc}}( #1 )',
                    '\\Scr': '\\mathscr{S}',
                    '\\tmpr': '\\mathscr{S}',
                    '\\limnf': '\\liminf \\limits_{#1}',
                    '\\limsp': '\\limsup \\limits_{#1}',
                    '\\R': '{\\mathbb R}',
                    '\\C': '{\\mathbb C}',
                    '\\N': '{\\mathbb N}',
                    '\\Q': '{\\mathbb Q}',
                    '\\H': '{\\mathbb H}',
                    '\\S': '{\\mathbb S}',
                    '\\Z': '{\\mathbb Z}',
                    '\\E': '{\\mathbb E}',
                    '\\Var': '\\mathsf{Var}',
                    '\\Cov': '\\mathsf{Cov}',
                    '\\KL': '\\mathsf{KL}',
                    '\\Ent': '\\mathsf{Ent}',
                    '\\F': '{\\mathbb F}',
                    '\\Acl': '\\mathcal{A}',
                    '\\Bcl': '\\mathcal{B}',
                    '\\Ccl': '\\mathcal{C}',
                    '\\Dcl': '\\mathcal{D}',
                    '\\Ecl': '\\mathcal{E}',
                    '\\Fcl': '\\mathcal{F}',
                    '\\Gcl': '\\mathcal{G}',
                    '\\Hcl': '\\mathcal{H}',
                    '\\Jcl': '\\mathcal{J}',
                    '\\Kcl': '\\mathcal{K}',
                    '\\Lcl': '\\mathcal{L}',
                    '\\Mcl': '\\mathcal{M}',
                    '\\Ncl': '\\mathcal{N}',
                    '\\Ocl': '\\mathcal{O}',
                    '\\Pcl': '\\mathcal{P}',
                    '\\Qcl': '\\mathcal{Q}',
                    '\\Rcl': '\\mathcal{R}',
                    '\\Scl': '\\mathcal{S}',
                    '\\Tcl': '\\mathcal{T}',
                    '\\Ucl': '\\mathcal{U}',
                    '\\Vcl': '\\mathcal{V}',
                    '\\Wcl': '\\mathcal{W}',
                    '\\Xcl': '\\mathcal{X}',
                    '\\Ycl': '\\mathcal{Y}',
                    '\\Zcl': '\\mathcal{Z}',
                    '\\diag': '\\mathrm{diag}',
                    '\\supp': '\\mathrm{supp}',
                    '\\diam': '\\mathrm{diam}',
                    '\\sgn': '\\mathrm{sgn}',
                    '\\im': '\\mathrm{Im}',
                    '\\lcm': '\\mathrm{lcm}',
                    '\\aut': '\\mathrm{Aut}',
                    '\\inn': '\\mathrm{Inn}',
                    '\\rg': '\\mathrm{rg}',
                    '\\vol': '\\mathrm{vol}',
                    '\\Pr': '\\mathrm{Pr}',
                    '\\Tr': '\\mathrm{Tr}',
                    '\\eps': '\\varepsilon',
                    '\\charfct': '\\mathds{1}',
                    '\\nullfct': '{\\bf 0}',
                    '\\as': '\\text{a.s.}\\xspace',
                    '\\argmax': '\\mathop{\\mathrm{arg\\,max}}',
                    '\\argmin': '\\mathop{\\mathrm{arg\\,min}}',
                    '\\esssup': '\\mathop{\\mathrm{ess\\,sup}}',
                    '\\th': '\\hat{\\theta}',
                    '\\pto': '\\stackrel{p}{\\longrightarrow}',
                    '\\dto': '\\stackrel{d}{\\longrightarrow}',
                    '\\asto': '\\stackrel{a.s.}{\\longrightarrow}',
                    '\\coloneqq': ':='
                }
            });">
            </script>
    </head>
    <body>
        <div class="row">
            <div class="col-lg-12 col-xl-8 offset-xl-2"> 
            <h1>Gaussian Location Model</h1>
<hr />
<p>
<strong>Definition</strong>: the $d$-dimensional Gaussian location model with noise $\sigma^2$ is the family of distributions $\Pcl = \{\Ncl(\theta, \sigma^2 I_d) : \theta \in \R^d\}$.
</p>
<hr />
<p>
It is possible to generalize this family by adding a constraint set $\theta \in \Theta \subseteq \R^d$. For example, $\Theta$ could contain vectors that are sparse, monotonically increasing, constrained to a subspace, etc.
</p>
<h2 id="testing-to-estimation-gap">Testing-to-Estimation Gap</h2>
<h3 id="minimax-testing-radius-for-gaussian-location-model">Minimax testing radius for Gaussian location model</h3>
<p>
Given i.i.d. samples $X_1, \ldots, X_n$, we would like to test the hypotheses
$$
\begin{cases}
H_0 : X_1, \ldots, X_n \sim \Ncl(0, \sigma_2I_d) \\
H_1 : X_1, \ldots, X_n \sim \Ncl(\theta, \sigma_2I_d).
\end{cases}
$$
We can argue that the sample mean $X_n = \frac{1}{n}(X_1 + \ldots + X_n)$ is a sufficient statistic and thereby reduce the testing problem to
$$
\begin{cases}
H_0 : \hat{X}_n \sim \Ncl(0, \frac{\sigma^2}{n} I_d) \\
H_1 : \hat{X}_n \sim \Ncl(\theta, \frac{\sigma^2}{n} I_d).
\end{cases}
$$
To see why it is a sufficient statistic, note that the Gaussian PDF can be written in terms of $(\hat{X}_n, X_1 - \hat{X}_n, \ldots, X_n - \hat{X}_n)$, and all the terms $X_i - \hat{X}_n$ are invariant to changes in the mean.
</p>
<hr />
<p>
<strong>Theorem (Minimax radius for Gaussian Means Testing)</strong>. consider a hypothesis testing problem with null distribution $H_0 : \Ncl(0, \frac{\sigma^2}{n} I_d)$ and composite alternative $H_1 : \Ncl(\theta, \frac{\sigma^2}{n}I_d)$ for $\theta \in \Theta \subseteq \R^d$.
</p>
<p>
First, in the unconstrained case ($\Theta = \R^d$), the <a href="Hypothesis Testing.html#composite-hypothesis-testing">minimax testing radius</a> is given (up to constants) by $\eps^2 \sim \sigma^2 \sqrt{d}/n$.
</p>
<p>
Second, in the general case, we have the lower bound
$$\Ecl_{\mathsf{mm}}(P_0, \Pcl_\eps, \Psi) \geq \frac{1}{2}\left( 1 - \sqrt{\E_{\theta, \theta' \sim \pi} \exp ( \langle \theta, \theta' \rangle ) - 1 }\right)
$$
where $\Pcl_\eps = \{\Ncl(\theta, \sigma^2 I_d) : \theta \in \Theta \setminus B_\eps (0)\}$ and $\pi$ is a prior over $\Theta$ that is supported on $\Theta \setminus B_\eps(0)$.
</p>
<hr />
<p>
<em>Proof</em>. first, we show the lower bound.
</p>
<ol>
<li>Reduction to Bayesian testing: for any prior $\pi$ supported on $\Theta \setminus B_\eps(0)$, it is clear that
</li>
</ol>
<p>
$$
\begin{aligned}
\Ecl_{\mathsf{mm}}(P_0, \Pcl_\eps, \Psi) & = \sup_{P_\theta \in \Pcl_\eps} \Ecl_{1/2}(P_0, P_\theta, \Psi)  \geq \E_{\theta \sim \pi}\left[ \Ecl_{1/2}(P_0, P_\theta, \Psi)\right].
\end{aligned}
$$
</p>
<ol>
<li>By <a href="Le Cam's Bound.html">Le Cam's Bound</a>,
</li>
</ol>
<p>
$$
\E_{\theta \sim \pi}[\Ecl_{1/2}(P_0, P_\theta, \Psi)] \geq \frac{1}{2}\left( 1 - \E_{\theta \sim \pi}[\|P_0 - P_\theta\|_{\mathsf{TV}}]\right)
$$
</p>
<ol>
<li>It turns out that $\|P - Q\|_{\mathsf{TV}} \leq \sqrt{\chi^2(P \mid Q)}$ which is useful because the $\chi^2$-divergence between Gaussian mixtures has <a class="broken" href="#">a nice closed form</a>.  For $Q_\pi(x) = \E_{\theta \sim \pi}[P_\theta(x)]$,
</li>
</ol>
<p>
$$
\chi^2(Q_\pi \mid P_0) = \E_{\theta, \theta' \sim \pi}[\exp(\langle \theta' , \theta \rangle)] - 1.
$$
</p>
<ol>
<li>We need to construct a mixing distribution $\pi$ that minimizes $\chi^2(Q_\pi \mid P_0)$, subject to the constraint that $\supp(\pi) \subseteq B(0, \eps)^c$. One option is to take $\theta_i = \frac{\eps}{\sqrt{d}} Z_i$ where $Z_i \sim \mathsf{Unif}(\{-1, 1\})$. Clearly, $\|\theta\|_2^2 = \eps^2$ always, and since $Z_i Z_i' \stackrel{(d)}{=} Z_0$, we have by Hoeffding's bound that
</li>
</ol>
<p>
$$
\log \E_{\theta, \theta'} \exp (\langle \theta', \theta \rangle) = d \log \E_{Z, Z'}\left[ \exp \left(\frac{\eps^2}{d} Z Z'\right) \right] \leq\frac{ \eps^4}{2d}.
$$
</p>
<ol>
<li>This implies that for $\eps^2 = \sqrt{2cd}$, $\chi^2(Q_\pi \mid P) \leq \sqrt{e^c - 1}$ and for a sufficiently small constant the claim follows.
</li>
</ol>
<p>
<strong>Remark</strong>: at a high level, we are basically deriving a relationship between $\E_{\theta \sim \pi}[\Ecl(P_0, P_\theta, \Psi)]$ and $\chi^2(Q_\theta \mid P_0)$. The closer the two distributions in $\chi^2$, the harder the testing problem, and hence the larger the error.
</p>
<h3 id="mean-estimation-for-gaussian-location-model">Mean estimation for Gaussian location model</h3>
<p>
Rather than testing whether the mean is zero, we might ask how many samples are required to estimate the true mean. By <a href="Cramer-Rao Lower Bound.html">Cramer-Rao</a>, as $n \to \infty$ we have
$$
\E[\|\hat{\theta}^{\mathsf{MLE}}_n - \theta\|^2_2] \geq \mathsf{Tr}(I(\theta)^{-1}) = \frac{\sigma^2d}{n}
$$
<del>Seems like this should actually be d/n^2</del>?
</p>
            </div>
        </div>
        <div class="row">
        <p style="text-align: right; width:100%"><i><a href="../miscellany.html">Back...</a></i></p>
        </div>
    </body>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
    crossorigin="anonymous"></script>
</html>
