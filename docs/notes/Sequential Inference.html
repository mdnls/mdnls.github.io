
<!DOCTYPE html>
    <head>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" type="text/css" href="../styles/styles.css">
        <link rel="icon" href="assets/icon.ico" />
        <meta name="google-site-verification" content="gGsyj98Hmr9mZj0-DQzJIAdOP3eJXZJZnM4_NF8Mai8" />
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"> 
        <title>Mara Daniels - MIT</title>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
            onload="renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                ],
                macros: {
                    '\\saeq': '\\{#1\\}',
                    '\\linf': '\\lim_{n \\to \\infty}',
                    '\\Alpha': '\\mathcal{A}',
                    '\\norm': '\\left\\lVert#1\\right\\rVert',
                    '\\ct': 'C^\\infty_c ( #1 )',
                    '\\lloc': 'L^1_{\\mathsf{loc}}( #1 )',
                    '\\Scr': '\\mathscr{S}',
                    '\\tmpr': '\\mathscr{S}',
                    '\\limnf': '\\liminf \\limits_{#1}',
                    '\\limsp': '\\limsup \\limits_{#1}',
                    '\\R': '{\\mathbb R}',
                    '\\C': '{\\mathbb C}',
                    '\\N': '{\\mathbb N}',
                    '\\Q': '{\\mathbb Q}',
                    '\\H': '{\\mathbb H}',
                    '\\S': '{\\mathbb S}',
                    '\\Z': '{\\mathbb Z}',
                    '\\E': '{\\mathbb E}',
                    '\\Var': '\\mathsf{Var}',
                    '\\Cov': '\\mathsf{Cov}',
                    '\\KL': '\\mathsf{KL}',
                    '\\Ent': '\\mathsf{Ent}',
                    '\\F': '{\\mathbb F}',
                    '\\Acl': '\\mathcal{A}',
                    '\\Bcl': '\\mathcal{B}',
                    '\\Ccl': '\\mathcal{C}',
                    '\\Dcl': '\\mathcal{D}',
                    '\\Ecl': '\\mathcal{E}',
                    '\\Fcl': '\\mathcal{F}',
                    '\\Gcl': '\\mathcal{G}',
                    '\\Hcl': '\\mathcal{H}',
                    '\\Jcl': '\\mathcal{J}',
                    '\\Kcl': '\\mathcal{K}',
                    '\\Lcl': '\\mathcal{L}',
                    '\\Mcl': '\\mathcal{M}',
                    '\\Ncl': '\\mathcal{N}',
                    '\\Ocl': '\\mathcal{O}',
                    '\\Pcl': '\\mathcal{P}',
                    '\\Qcl': '\\mathcal{Q}',
                    '\\Rcl': '\\mathcal{R}',
                    '\\Scl': '\\mathcal{S}',
                    '\\Tcl': '\\mathcal{T}',
                    '\\Ucl': '\\mathcal{U}',
                    '\\Vcl': '\\mathcal{V}',
                    '\\Wcl': '\\mathcal{W}',
                    '\\Xcl': '\\mathcal{X}',
                    '\\Ycl': '\\mathcal{Y}',
                    '\\Zcl': '\\mathcal{Z}',
                    '\\diag': '\\mathrm{diag}',
                    '\\supp': '\\mathrm{supp}',
                    '\\diam': '\\mathrm{diam}',
                    '\\sgn': '\\mathrm{sgn}',
                    '\\im': '\\mathrm{Im}',
                    '\\lcm': '\\mathrm{lcm}',
                    '\\aut': '\\mathrm{Aut}',
                    '\\inn': '\\mathrm{Inn}',
                    '\\rg': '\\mathrm{rg}',
                    '\\vol': '\\mathrm{vol}',
                    '\\Pr': '\\mathrm{Pr}',
                    '\\Tr': '\\mathrm{Tr}',
                    '\\eps': '\\varepsilon',
                    '\\charfct': '\\mathds{1}',
                    '\\nullfct': '{\\bf 0}',
                    '\\as': '\\text{a.s.}\\xspace',
                    '\\argmax': '\\mathop{\\mathrm{arg\\,max}}',
                    '\\argmin': '\\mathop{\\mathrm{arg\\,min}}',
                    '\\esssup': '\\mathop{\\mathrm{ess\\,sup}}',
                    '\\th': '\\hat{\\theta}',
                    '\\pto': '\\stackrel{p}{\\longrightarrow}',
                    '\\dto': '\\stackrel{d}{\\longrightarrow}',
                    '\\asto': '\\stackrel{a.s.}{\\longrightarrow}',
                    '\\coloneqq': ':='
                }
            });">
            </script>
    </head>
    <body>
        <div class="row">
            <div class="col-lg-12 col-xl-8 offset-xl-2"> 
            <h1>Sequential Inference</h1>
<p>
The goal in sequential inference is to develop a statistical model with some notion of 'time dependence' or 'memory.'
</p>
<hr />
<p>
<strong>Example (Discrete Time)</strong>:  we assume the following model for the random process $(X_t, Y_t)_{t \in \N}$. The initial condition is $X_0 \sim \pi_0$ with dynamics,
$$X_{t+1} \sim f_{t+1}(X_{t+1}\mid X_t) \qquad Y_{t+1} \sim g_{t+1}(Y_{t+1} \mid X_{t+1})$$
where $X_{t+1}, Y_{t+1}$ are <em>conditionally independent</em> of all other $(X_s, Y_s)_{s \not \in \{t, t-1\}}$ in the model.
</p>
<p>
We call $(X_t)_{t \in \N}$ the <em>state variables</em> and $(Y_t)_{t \in \N}$ the <em>observed variables</em>. The standard problem is to estimate $(X_t)_{t \in \N}$ conditioned on the observations $(Y_t)_{t\in \N}$.
</p>
<hr />
<hr />
<p>
<strong>Example (Continuous Time)</strong>:
$$
\begin{aligned}
d X_t & = v(X_t) \, dt + \sigma(X_t) \, d W_t \\
Y_t & = g_t(X_t, \omega).
\end{aligned}
$$
</p>
<hr />
<p>
Our current sampling strategies for Bayesian inference are not necessarily well-suited to online problems. For example, in the discrete time model, the full conditional densities are available, so we <em>could</em> sample with MCMC/Gibbs/etc:
$$
p(X_{t^*} \mid Y_{0:t^*}, X_{\lnot t^*}) \propto g_{t^*}(Y_{t^*} \mid X_{t^*})f_{t^*}(X_{t^*} \mid X_{t^*-1}) f_{t^*+1} (X_{t^*+1} \mid X_{t^*})
$$
Unfortunately, the work required to sample this distribution depends recursively on many evaluations of the above quantity. To sample $p(X_{t^*+1} \mid Y_{0:t^*+1}, X_{\lnot t^*+1})$, we have to re-do all this work! This problem motivates specialized algorithms like <a href="Kalman Filtering.html">Kalman Filtering</a>.
</p>
<h3 id="canonical-problems">Canonical Problems</h3>
<p>
Some of the canonical problems we may wish to solve in the sequential inference model are:
</p>
<ol>
<li><strong>Filtering</strong>: at each time $t \in \N$, we would like to estimate $p(X_t \mid Y_{0 : t})$ in an online way. That is, stepping from $t \to t+1$ requires $O(1)$ effort and does not increase the estimation error.
</li>
<li><strong>Smoothing</strong>: at a fixed time $t \in \N$, we would like to estimate $p(X_t \mid Y_{0 : s})$ for some $s \geq t$. In this case, the hope is that learning future information (at time $s$) may improve what we know at time $t$.
</li>
<li><strong>Prediction</strong>: at a fixed time $t \in \N$, we would like to estimate $p(X_t \mid Y_{0:s})$ for some $s < t$. In this case, the hope is to predict future behavior given current knowledge up to time $s < t$.
</li>
<li><strong>Joint state-parameter inference</strong>: a 'meta-problem' in which we assume the transition functions depend on a parameter:  $$X_{t+1} \sim f_{t+1}(X_{t+1}\mid X_t, \theta) \qquad Y_{t+1} \sim g_{t+1}(Y_{t+1} \mid X_{t+1}, \theta)$$
</li>
</ol>
<p>
and the goal is to jointly estimate $\theta$ and solve one of the previous problems.
</p>
            </div>
        </div>
        <div class="row">
        <p style="text-align: right; width:100%"><i><a href="../miscellany.html">Back...</a></i></p>
        </div>
    </body>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
    crossorigin="anonymous"></script>
</html>
