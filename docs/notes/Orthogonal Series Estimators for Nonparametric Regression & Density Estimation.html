
<!DOCTYPE html>
    <head>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" type="text/css" href="../styles/styles.css">
        <link rel="icon" href="assets/icon.ico" />
        <meta name="google-site-verification" content="gGsyj98Hmr9mZj0-DQzJIAdOP3eJXZJZnM4_NF8Mai8" />
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"> 
        <title>Mara Daniels - MIT</title>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
            onload="renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                ],
                macros: {
                    '\\saeq': '\\{#1\\}',
                    '\\linf': '\\lim_{n \\to \\infty}',
                    '\\Alpha': '\\mathcal{A}',
                    '\\norm': '\\left\\lVert#1\\right\\rVert',
                    '\\ct': 'C^\\infty_c ( #1 )',
                    '\\lloc': 'L^1_{\\mathsf{loc}}( #1 )',
                    '\\Scr': '\\mathscr{S}',
                    '\\tmpr': '\\mathscr{S}',
                    '\\limnf': '\\liminf \\limits_{#1}',
                    '\\limsp': '\\limsup \\limits_{#1}',
                    '\\R': '{\\mathbb R}',
                    '\\C': '{\\mathbb C}',
                    '\\N': '{\\mathbb N}',
                    '\\Q': '{\\mathbb Q}',
                    '\\H': '{\\mathbb H}',
                    '\\S': '{\\mathbb S}',
                    '\\Z': '{\\mathbb Z}',
                    '\\E': '{\\mathbb E}',
                    '\\Var': '\\mathsf{Var}',
                    '\\Cov': '\\mathsf{Cov}',
                    '\\KL': '\\mathsf{KL}',
                    '\\Ent': '\\mathsf{Ent}',
                    '\\F': '{\\mathbb F}',
                    '\\Acl': '\\mathcal{A}',
                    '\\Bcl': '\\mathcal{B}',
                    '\\Ccl': '\\mathcal{C}',
                    '\\Dcl': '\\mathcal{D}',
                    '\\Ecl': '\\mathcal{E}',
                    '\\Fcl': '\\mathcal{F}',
                    '\\Gcl': '\\mathcal{G}',
                    '\\Hcl': '\\mathcal{H}',
                    '\\Jcl': '\\mathcal{J}',
                    '\\Kcl': '\\mathcal{K}',
                    '\\Lcl': '\\mathcal{L}',
                    '\\Mcl': '\\mathcal{M}',
                    '\\Ncl': '\\mathcal{N}',
                    '\\Ocl': '\\mathcal{O}',
                    '\\Pcl': '\\mathcal{P}',
                    '\\Qcl': '\\mathcal{Q}',
                    '\\Rcl': '\\mathcal{R}',
                    '\\Scl': '\\mathcal{S}',
                    '\\Tcl': '\\mathcal{T}',
                    '\\Ucl': '\\mathcal{U}',
                    '\\Vcl': '\\mathcal{V}',
                    '\\Wcl': '\\mathcal{W}',
                    '\\Xcl': '\\mathcal{X}',
                    '\\Ycl': '\\mathcal{Y}',
                    '\\Zcl': '\\mathcal{Z}',
                    '\\diag': '\\mathrm{diag}',
                    '\\supp': '\\mathrm{supp}',
                    '\\diam': '\\mathrm{diam}',
                    '\\sgn': '\\mathrm{sgn}',
                    '\\im': '\\mathrm{Im}',
                    '\\lcm': '\\mathrm{lcm}',
                    '\\aut': '\\mathrm{Aut}',
                    '\\inn': '\\mathrm{Inn}',
                    '\\rg': '\\mathrm{rg}',
                    '\\vol': '\\mathrm{vol}',
                    '\\Pr': '\\mathrm{Pr}',
                    '\\Tr': '\\mathrm{Tr}',
                    '\\eps': '\\varepsilon',
                    '\\charfct': '\\mathds{1}',
                    '\\nullfct': '{\\bf 0}',
                    '\\as': '\\text{a.s.}\\xspace',
                    '\\argmax': '\\mathop{\\mathrm{arg\\,max}}',
                    '\\argmin': '\\mathop{\\mathrm{arg\\,min}}',
                    '\\esssup': '\\mathop{\\mathrm{ess\\,sup}}',
                    '\\th': '\\hat{\\theta}',
                    '\\pto': '\\stackrel{p}{\\longrightarrow}',
                    '\\dto': '\\stackrel{d}{\\longrightarrow}',
                    '\\asto': '\\stackrel{a.s.}{\\longrightarrow}',
                    '\\coloneqq': ':='
                }
            });">
            </script>
    </head>
    <body>
        <div class="row">
            <div class="col-lg-12 col-xl-8 offset-xl-2"> 
            <h1>Orthogonal Series Estimators for Nonparametric Regression & Density Estimation</h1>
<p>
Consider a nonparametric regression problem with i.i.d. data of the form $\{(x_i, y_i)\}_{i=1}^n$ where
$$
y_i = f(x_i) + w_i
$$
and the $x_i \sim P$ are data., the $w_i$ represent noise, and $f(x) :[0, 1]^d \to \R$ is a generic function of interest. An Orthogonal Series Estimator is a procedure that is designed to estimate the coefficients of $f$ with respect to an orthonormal basis $\{\phi^{(\alpha)} \}_{\alpha \in \N^d}$ of $\Lcl^2([0, 1]^d)$.
</p>
<hr />
<p>
<strong>Proposition (Bias-Variance Tradeoff)</strong>. suppose that the following assumptions hold:
</p>
<ol>
<li>Noise assumptions
<ul>
<li>Zero conditional mean: $\E[w_i | x_i] = 0$
</li>
<li>Bounded variance $\E[w_i^2 | x_i ] \leq \gamma^2$.
</li>
</ul>
</li>
<li>Data assumption: $\Var_{X \sim P}(f(X) \phi^\alpha(X)) \leq \sigma^2$.
</li>
</ol>
<p>
Let $u_\alpha = \E_{P}[f(X) \phi^\alpha(X)]$ and define the $M$-th order orthogonal series estimator by,
$$
\hat{f}(x) = \sum_{|\alpha| < M} \hat{u}_{\alpha} \phi^\alpha(x) \qquad \hat{u}_\alpha = \frac{1}{n}\sum_{i=1}^n y_i \phi^\alpha(x_i)
$$
Then, the mean squared error is bounded by
$$
\E_{x \sim P}\ \E_{\Scl}\ [|\hat{f}(x) - f(x)|^2] \leq \underbrace{\sum_{|\alpha|\geq M} u_\alpha^2}_{\text{bias term}} + \underbrace{\frac{M^d(\sigma^2 + \gamma^2)}{n}}_{\text{variance term}}.
$$
where the expectation is taken over $\Scl = \{(x_i, y_i)\}_{i=1}^n \sim P$ i.i.d.
</p>
<hr />
<p>
<em>Proof</em>. the population average estimator is
$$
\begin{aligned}
\bar{f}(x) \coloneqq \E_{\Scl}[\hat{f}(x)]= \sum_{|\alpha| \leq M}u_\alpha \phi^\alpha(x)
\end{aligned}
$$
so the bias is
$$ \E_{x \sim P}[\|\bar{f}(x) - f(x)\|^2] = \|\bar{f} - f\|_{\Lcl^2(P)}^2 = \sum_{|\alpha|>M} u_\alpha^2 $$
and the variance is
$$
\E_{x \sim P} \ \E_{\Scl} \left[ \left\| \sum_{|\alpha|<M} (\hat{u}_\alpha - u_\alpha) \phi^\alpha(x)\right\|^2\right] = \sum_{|\alpha|\leq M}\E_{\Scl} [(\hat{u}_\alpha - u_\alpha)^2] = \sum_{|\alpha|\leq M}\Var \left( \frac{1}{n}\sum_{i=1}^n (f(x_i) + w_i) \phi^\alpha(x_i)) \right).
$$
Using the tower property of variance, we can apply both the assumptions on the noise:
$$
\begin{aligned}
\Var(w_i \phi^\alpha(x_i)) & = \E_{x \sim P}[\Var(w_i \phi^\alpha(x_i) \mid x_i=x)]  + \Var_{x \sim P}\left( \E[w_i \phi^\alpha(x_i) \mid x_i = x]\right) \\
& = \E_{x \sim P} [\phi^\alpha(x)^2 \E[w_i^2 \mid x_i =x ]]\\
& \leq \gamma^2
\end{aligned}
$$
and so, along with the assumption $\Var(f(x) \phi^\alpha(x)) \leq \sigma^2$, the variance term is bound by
$$
\sum_{|\alpha|< M} \frac{\sigma^2 + \gamma^2}{n}.
$$
It remains to bound the number of indices in this sum $\#\{|\alpha| \leq M\} \leq (M+1)^d$, which is a crude bound that follows from the observation that each of the $d$ indices of $\alpha$ can take at most $M$ values.
</p>
<h3 id="examples-applications">Examples & Applications</h3>
<h3 id="sobolev-ellipses">Sobolev Ellipses</h3>
<p>
A common smoothness assumption for $f : [0, 1]^d \to \R$ is that its coefficients satisfy a <a href="Orthogonal Series Estimators for Nonparametric Regression & Density Estimation.html#sobolev-ellipses">generalized Sobolev condition</a>,
$$
\sum_{\alpha \in \N^d} u_\alpha^2 \alpha^{2s} \leq B < \infty
$$
where $s \in \R$ is a smoothness parameter and where $\alpha^s \coloneqq \left(\prod_{i \leq d}|\alpha_i|\right)^{s}$. For example, when $P(x)$ is uniform and $\phi^{\alpha}(x)$ are Fourier coefficients, then this condition is equivalent to $s$-times differentiability in each coordinate (and in particular, the left hand side is the $\Lcl^2(P)$ norm of $(\partial^{(s)}_1 \partial^{(s)}_2 \dots \partial^{(s)}_d f)(x)$).
</p>
<p>
So we can bound the bias term by,
$$
\sum_{|\alpha| \geq M}u_\alpha^2  \leq \sum_{|\alpha|\geq M} u_\alpha^2\left(\frac{|\alpha|}{M}\right)^{2s} \lesssim \frac{1}{M^{2s}} \sum_{|\alpha|\geq M} \alpha^{2s} u_\alpha^2 \leq \frac{B}{M^{2s}}.
$$
<ins>The notation here is a bit unclear:</ins> $|\alpha| = \|\alpha\|_1$ <ins>and we are using the inequality</ins> $|\alpha|^{2s} \leq \alpha^{2s}$ <ins>since the right hand side is the product of coordinates.</ins>
</p>
<hr />
<p>
<strong>Theorem (Non-parametric Rate for Sobolev Estimation)</strong>:  suppose that $f$ satisfies a <a href="Orthogonal Series Estimators for Nonparametric Regression & Density Estimation.html">generalized Sobolev condition</a>. Then, the orthogonal series estimator has mean squared error
$$
\E_{x \sim P}\ \E_{\Scl}\ [|\hat{f}(x) - f(x)|^2] \lesssim \frac{1}{M^{2s}} + \frac{M^d(\sigma^2 + \gamma^2)}{n} \lesssim n^{-\frac{2s}{2s+d}}
$$
which is attained by cutoff $M \sim n^{-\frac{1}{2s+d}}$.
</p>
<hr />
            </div>
        </div>
        <div class="row">
        <p style="text-align: right; width:100%"><i><a href="../miscellany.html">Back...</a></i></p>
        </div>
    </body>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
    crossorigin="anonymous"></script>
</html>
