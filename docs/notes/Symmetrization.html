
<!DOCTYPE html>
    <head>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" type="text/css" href="../styles/styles.css">
        <link rel="icon" href="assets/icon.ico" />
        <meta name="google-site-verification" content="gGsyj98Hmr9mZj0-DQzJIAdOP3eJXZJZnM4_NF8Mai8" />
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"> 
        <title>Mara Daniels - MIT</title>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
            onload="renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                ],
                macros: {
                    '\\saeq': '\\{#1\\}',
                    '\\linf': '\\lim_{n \\to \\infty}',
                    '\\Alpha': '\\mathcal{A}',
                    '\\norm': '\\left\\lVert#1\\right\\rVert',
                    '\\ct': 'C^\\infty_c ( #1 )',
                    '\\lloc': 'L^1_{\\mathsf{loc}}( #1 )',
                    '\\Scr': '\\mathscr{S}',
                    '\\tmpr': '\\mathscr{S}',
                    '\\limnf': '\\liminf \\limits_{#1}',
                    '\\limsp': '\\limsup \\limits_{#1}',
                    '\\R': '{\\mathbb R}',
                    '\\C': '{\\mathbb C}',
                    '\\N': '{\\mathbb N}',
                    '\\Q': '{\\mathbb Q}',
                    '\\H': '{\\mathbb H}',
                    '\\S': '{\\mathbb S}',
                    '\\Z': '{\\mathbb Z}',
                    '\\E': '{\\mathbb E}',
                    '\\Var': '\\mathsf{Var}',
                    '\\Cov': '\\mathsf{Cov}',
                    '\\KL': '\\mathsf{KL}',
                    '\\Ent': '\\mathsf{Ent}',
                    '\\F': '{\\mathbb F}',
                    '\\Acl': '\\mathcal{A}',
                    '\\Bcl': '\\mathcal{B}',
                    '\\Ccl': '\\mathcal{C}',
                    '\\Dcl': '\\mathcal{D}',
                    '\\Ecl': '\\mathcal{E}',
                    '\\Fcl': '\\mathcal{F}',
                    '\\Gcl': '\\mathcal{G}',
                    '\\Hcl': '\\mathcal{H}',
                    '\\Jcl': '\\mathcal{J}',
                    '\\Kcl': '\\mathcal{K}',
                    '\\Lcl': '\\mathcal{L}',
                    '\\Mcl': '\\mathcal{M}',
                    '\\Ncl': '\\mathcal{N}',
                    '\\Ocl': '\\mathcal{O}',
                    '\\Pcl': '\\mathcal{P}',
                    '\\Qcl': '\\mathcal{Q}',
                    '\\Rcl': '\\mathcal{R}',
                    '\\Scl': '\\mathcal{S}',
                    '\\Tcl': '\\mathcal{T}',
                    '\\Ucl': '\\mathcal{U}',
                    '\\Vcl': '\\mathcal{V}',
                    '\\Wcl': '\\mathcal{W}',
                    '\\Xcl': '\\mathcal{X}',
                    '\\Ycl': '\\mathcal{Y}',
                    '\\Zcl': '\\mathcal{Z}',
                    '\\diag': '\\mathrm{diag}',
                    '\\supp': '\\mathrm{supp}',
                    '\\diam': '\\mathrm{diam}',
                    '\\sgn': '\\mathrm{sgn}',
                    '\\im': '\\mathrm{Im}',
                    '\\lcm': '\\mathrm{lcm}',
                    '\\aut': '\\mathrm{Aut}',
                    '\\inn': '\\mathrm{Inn}',
                    '\\rg': '\\mathrm{rg}',
                    '\\vol': '\\mathrm{vol}',
                    '\\Pr': '\\mathrm{Pr}',
                    '\\Tr': '\\mathrm{Tr}',
                    '\\eps': '\\varepsilon',
                    '\\charfct': '\\mathds{1}',
                    '\\nullfct': '{\\bf 0}',
                    '\\as': '\\text{a.s.}\\xspace',
                    '\\argmax': '\\mathop{\\mathrm{arg\\,max}}',
                    '\\argmin': '\\mathop{\\mathrm{arg\\,min}}',
                    '\\esssup': '\\mathop{\\mathrm{ess\\,sup}}',
                    '\\th': '\\hat{\\theta}',
                    '\\pto': '\\stackrel{p}{\\longrightarrow}',
                    '\\dto': '\\stackrel{d}{\\longrightarrow}',
                    '\\asto': '\\stackrel{a.s.}{\\longrightarrow}',
                    '\\coloneqq': ':='
                }
            });">
            </script>
    </head>
    <body>
        <div class="row">
            <div class="col-lg-12 col-xl-8 offset-xl-2"> 
            <h1>Symmetrization</h1>
<p>
Symmetrization is a powerful tool for reasoning about the Gaussian-like behavior of sums of independent random variables. To see the basic idea, consider a sum of i.i.d. random variables $\sum_{i=1}^n X_i - \E[X_i]$. In the worst case, the size of the sum could be $O(n)$, since there are $n$ terms each roughly of size $\sqrt{\Var(X)}$. But when the CLT holds, the typical behavior of the sum is actually $O(\sqrt{n})$. The explanation for this discrepancy is the fact that the terms $X_i - \E[X_i]$ have different signs and they cancel each other out! The symmetrization argument is a way to make this intuition explicit.
</p>
<hr />
<p>
<strong>Proposition (basic symmetrization)</strong>. Let $X_1, \ldots, X_n \sim \mu$ be i.i.d. real-valued random variables and let $\Phi : \R \to \R$ be any symmetric convex function. Then we have
$$
\E \left[ \Phi \left( \sum_{i=1}^n X_i - \E[X_i]\right) \right]\leq \E\left[ \Phi \left( \sum_{i=1}^n \eps_i(X_i - X_i')\right)\right] \leq \E \left[ \Phi \left( 2 \sum_{i=1}^n X_i - \E[X_i]\right) \right]
$$
where $\eps_i \sim \mathsf{Unif}(\pm 1)$ are independent rademacher random variables and $X_i' \sim \mu$ are also i.i.d.
</p>
<hr />
<p>
<em>Proof</em>. By Jensen's:
$$
\E \left[ \Phi \left( \E_{X_i'\sim \mu}\left[ \sum_{i=1}^n (X_i - X_i')\right]\right) \right]\leq \E\left[ \Phi \left( \sum_{i=1}^n \eps_i(X_i - X_i')\right)\right]
$$
where we used the fact that $X_i - X_i' \stackrel{(d)}{=} \eps_i(X_i - X_i')$. For the second inequality, observe that
$$
\Phi\left( \sum_{i=1}^n (X_i - X_i')\right) = \Phi \left( \frac{1}{2} \left(2 \sum_{i=1}^n(X_i - \E[X_i]) +2 \sum_{i=1}^n (\E[X_i'] - X_i')\right)\right) \leq \Phi\left( 2 \sum_{i=1}^n X_i - \E[X_i] \right)
$$
by convexity. <span class="qed" />
</p>
<h2 id="application-to-empirical-processes">Application to Empirical Processes</h2>
<hr />
<p>
<strong>Proposition (rademacher symmetrization bound)</strong>. let $X_1, \ldots, X_n \sim \mu$ be i.i.d. random variables and let $G_n(f)$ be the associated empirical process:
$$
G_n(f) = \frac{1}{\sqrt{n}} \sum_{i=1}^n (f(X_i) - \E_\mu[f(X)]).
$$
Then, for $\eps_i \sim \mathsf{Unif}(\pm1)$, it holds that
$$
\E\left[\sup_{f \in \Fcl}G_n(f)\right] \leq  \E \left[ \sup_{f \in \Fcl} \frac{1}{\sqrt{n}}\sum_{i=1}^n\eps_i(f(X_i) - f(X_i'))\right] \leq 2 \E\left[\sup_{f \in \Fcl}G_n(f)\right]
$$
It is also common to use the simpler form,
$$
\E \left[ \sup_{f \in \Fcl} G_n(f) \right] \leq 2 \E\left[ \sup_{f \in \Fcl} \frac{1}{\sqrt{n}} \sum_{i=1}^n \eps_i f(X_i)\right].
$$
</p>
<hr />
<p>
<em>Proof</em>. Just check that the supremum satisfies the continuity requirement in the basic symmetrization proposition. For the simpler form, use that
$$
\begin{aligned}
\E \left[ \sup_{f \in \Fcl} \frac{1}{\sqrt{n}}\sum_{i=1}^n\eps_i(f(X_i) - f(X_i'))\right] & \leq  \E \left[ \sup_{f \in \Fcl} \frac{1}{\sqrt{n}}\sum_{i=1}^n\eps_if(X_i) \right] + \E \left[ \sup_{f \in \Fcl} \frac{1}{\sqrt{n}}\sum_{i=1}^n(-\eps_i)f(X_i') \right] \\
& = 2 \E\left[ \sup_{f \in \Fcl} \frac{1}{\sqrt{n}} \sum_{i=1}^n \eps_i f(X_i)\right].
\end{aligned}
$$
<span class="qed" />
</p>
<p>
The power of this approach is that it can be used to tighten some applications of chaining inequalities like <a href="Dudley's Entropy Integral.html">Dudley's Entropy Integral</a>. Generally speaking, symmetrization gives a tighter characterization of the <a href="Stochastic Processes.html#concentration-propertiesconcentration-properties">sub-gaussianity</a> of the process. With a naive application of Hoeffding's inequality, $(G_n(f))_{f \in \Fcl}$ is sub-gaussian with respect to the metric $d(f, g) = \|f-g\|_\infty$. But after symmetrization, we can invoke concentration bounds with respect to $\eps_1, \ldots, \eps_n$ <em>conditionally</em> on the values of $X_1, \ldots, X_n$. Then we have,
$$
\log\E_{\eps_1, \ldots, \eps_n} \left[ \exp\left(\frac{\lambda}{\sqrt{n}}\sum_{i=1} \eps_i (f(X_i)-g(X_i))  \right) \bigg| X_1, \ldots, X_n\right] \leq \frac{\lambda^2}{2}\underbrace{\frac{1}{n}\sum_{i=1}^n (f(X_i) - g(X_i))^2}_{d_n(f, g)}
$$
so that the conditioned process is now sub-gaussian with respect to a <em>random metric</em> $d_n(f, g)$. By the law of large numbers, as $n \to \infty$ we expect
$$
d_n(f, g)^2 = \frac{1}{n} \sum_{i=1}^n(f(X_i) - g(X_i))^2 \longrightarrow \|f-g\|^2_{\Lcl^2(\mu)}.
$$
This is good news because coverings in $\|\cdot\|_{\Lcl^2(\mu)}$ (and often in $d_n(f, g)$) are significantly smaller than in $\|\cdot\|_{\infty}$. For further discussion, see
</p>
            </div>
        </div>
        <div class="row">
        <p style="text-align: right; width:100%"><i><a href="../miscellany.html">Back...</a></i></p>
        </div>
    </body>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
    crossorigin="anonymous"></script>
</html>
