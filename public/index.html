<!DOCTYPE html>
<head>
    
<meta name="viewport" content= "width=device-width, initial-scale=1.0">
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"> 
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="styles/styles.css">
<title>Mara Daniels - MIT</title>
<link rel="icon" href="assets/icon.ico" />

    <meta name="google-site-verification" content="gGsyj98Hmr9mZj0-DQzJIAdOP3eJXZJZnM4_NF8Mai8" />
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"> 
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="styles/styles.css">
    <title>Mara Daniels - MIT</title>
</head>
<body>
    <div class="row">
        <div class="offset-md-2 col-mr-4 col-md-4 col-xs-12 my-md-1 id="about">
            <h1 id="about">Mara Daniels</h1>
            <p><span id="email">maradan<span style="display:none">_</span></span> 
                <br/>
                <a href="https://scholar.google.com/citations?user=7hL2f54AAAAJ&hl=en">Scholar</a> : <a href="https://twitter.com/m_dnls">Twitter</a> : <a href="https://github.com/mdnls">GitHub</a>.
            </p>
            <p>I am an Applied Mathematics PhD candidate at MIT. My advisor is <a href="https://math.mit.edu/~rigollet">Phillipe Rigollet</a>. I am primarily interested in developing principled methodologies for deep machine learning, typically in the context of image generation and imaging or spatial inverse problems. Previously, I was fortunate to work under the supervision of <a href="https://khoury.northeastern.edu/home/hand/">Dr. Paul Hand</a> at Northeastern University and <a href="https://people.epfl.ch/lenka.zdeborova/?lang=en">Dr. Lenka Zdeborová</a> at EPFL.
            </p>
        </div>
        <div class="offset-md-1 col-md-4 col-xs-3 my-md-1 my-2">
            <img src="assets/Mara.jpeg" style="max-width: min(100%, 300px); height: auto; display: block;" />
        </div>
    </div>
    <div class="row">
        <div class="offset-md-2 col-md-8 col-xs-12">
            <h3>News</h3>
            <ul>
                <li><em>June 2025</em>. I am visiting the Simons Laufer institute for the <a href="https://www.slmath.org/summer-schools/1102">Statistical Optimal Transport</a> summer school.</li>
                <li><em>April 2025</em>. I am speaking at HU Berlin on the contractivity of stochastic interpolation flow.</li>
            </ul>
            <i>I am actively searching for motivated collaborators to work on <a href="#">Splat Regression Modeling</a>. If you are interested, please email me with a description of your background and interests.</i>
        </div>
    </div>
    <hr class="col-md-8" />
    <div class="row">
        <div class="offset-md-2 col-md-8 col-xs-12" >
            <h3 id="work">Publications</h3>
            <p><i>* indicates equal contribution.</i></p>
            <div class="row">
                <div class="col-12">
                    <a href="https://arxiv.org/abs/2205.13503">On the Contractivity of Stochastic Interpolation Flow</a>
                    <div class="inset">
                        <p><span class="feat">M. Daniels</span>.
                            <br/>
                            We investigate stochastic interpolation, a recently introduced framework for high dimensional sampling which bears many similarities to diffusion modeling. Like diffusion, stochastic interpolation involves sample generation through the simulation of a deterministic or stochastic evolution equation. We investigate these dynamics and prove bounds on <i>contractivity</i> of the system, uncovering some interesting comparisons to optimal transport theory.</p>
                    </div>
                    <a href="https://arxiv.org/abs/2205.13503">Multi-layer State Evolution Under Random Convolutional Design.</a>
                    <div class="inset">
                        <p><span class="feat">M. Daniels</span>*, Cédric Gerbelot*, Florent Krzakala, Lenka Zdeborová. <span class="feat">Published in NeurIPS 2022</span>.
                        <br/> 
                        We study signal recovery in a multi-layer model with convolutional matrices, which is a simple model for a convolutional neural network. We prove state evolution equations for Approximate Message Passing, an algorithm that can be used to compute posterior statistics in high dimensional Bayesian models. These equations provide a tractable method to predict signal recovery error in a large-size limit. </p>
                    </div>
                    <a href="https://arxiv.org/abs/2110.03237">Score-based Generative Neural Networks for Large-Scale Optimal Transport.</a>
                    <div class="inset">
                        <p><span class="feat">M. Daniels</span>, Tyler Maunu, Paul Hand. <span class="feat">Published in NeurIPS 2021</span>.
                        <br/>
                        We propose a new method to solve a regularized form of the Optimal Transport problem. The goal is to learn a transportation plan between a given source and target probability distribution so that the cost to execute that plan is minimized. We prove global optimization guarantees for a fast, large-scale learning algorithm to solve this problem and we demonstrate strong empirical performance.</p>
                    </div>
                    <a href="https://arxiv.org/abs/2102.11163">Generator Surgery for Compressed Sensing</a>
                    <div class="inset">
                        <p>Jung Yeon Park*, Niklas Smedemark-Marguilies*, <span class="feat">M. Daniels</span>, Rose Yu, Jan-Willem van de Meent, Paul Hand. Presented at <span class="feat">NeurIPS 2020 Deep Inverse Workshop</span>.
                        <br/> 
                        Generative priors for imaging inverse problems allow one to model images from a dataset by generating samples from the dataset. We demonstrate a simple method to improve recovery performance by modifying these priors after training, but this performance boost comes at the cost of no longer being able to generate samples using the prior.</p>
                    </div>
                    <a href="https://arxiv.org/abs/1905.11672">Invertible generative models for inverse problems: mitigating representation error and dataset bias.</a>
                    <div class="inset">
                        <p>Muhammad Asim*, <span class="feat">M. Daniels</span>*, Oscar Leong, Paul Hand, and Ali Ahmed. <span class="feat">Published in ICML 2020</span>.
                        <br/>
                        In an imaging inverse problem, one must recover missing information about a target image using prior assumptions on the image structure. We show that Invertible Neural Networks can be used to vastly outperform classical approaches when one has access to a dataset of known images.</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>

<script src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
  crossorigin="anonymous"></script>

</html>
